Args:
	mode: training
	batch_size: 64
	lr: 0.00015
	pt_lr: 1e-05
	weight_decay: 0.0005
	device: cuda
	num_epochs: 30


Model: AlexNet
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
AlexNet                                  [1, 100]                  --
├─Sequential: 1-1                        [1, 256, 2, 2]            --
│    └─Conv2d: 2-1                       [1, 64, 16, 16]           1,792
│    └─MaxPool2d: 2-2                    [1, 64, 8, 8]             --
│    └─ReLU: 2-3                         [1, 64, 8, 8]             --
│    └─Conv2d: 2-4                       [1, 192, 8, 8]            110,784
│    └─MaxPool2d: 2-5                    [1, 192, 4, 4]            --
│    └─ReLU: 2-6                         [1, 192, 4, 4]            --
│    └─Conv2d: 2-7                       [1, 384, 4, 4]            663,936
│    └─ReLU: 2-8                         [1, 384, 4, 4]            --
│    └─Conv2d: 2-9                       [1, 256, 4, 4]            884,992
│    └─ReLU: 2-10                        [1, 256, 4, 4]            --
│    └─Conv2d: 2-11                      [1, 256, 4, 4]            590,080
│    └─MaxPool2d: 2-12                   [1, 256, 2, 2]            --
│    └─ReLU: 2-13                        [1, 256, 2, 2]            --
├─Sequential: 1-2                        [1, 100]                  --
│    └─Dropout: 2-14                     [1, 1024]                 --
│    └─Linear: 2-15                      [1, 4096]                 4,198,400
│    └─ReLU: 2-16                        [1, 4096]                 --
│    └─Dropout: 2-17                     [1, 4096]                 --
│    └─Linear: 2-18                      [1, 4096]                 16,781,312
│    └─ReLU: 2-19                        [1, 4096]                 --
│    └─Linear: 2-20                      [1, 100]                  409,700
==========================================================================================
Total params: 23,640,996
Trainable params: 23,640,996
Non-trainable params: 0
Total mult-adds (M): 63.16
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.41
Params size (MB): 94.56
Estimated Total Size (MB): 94.99
==========================================================================================

# Training iterations per epoch : 704

------------------------------
|          Training          |
------------------------------

Epoch [101/130]:
		Specificity: 1.0
		Top 1 Acc = 47.38%
		Top 5 Acc = 75.92%                                 
		Loss/Iteration: 0.9010063217614185

Epoch [102/130]:
		Specificity: 1.0
		Top 1 Acc = 47.76%
		Top 5 Acc = 75.66%                                 
		Loss/Iteration: 0.8919384081593968

Epoch [103/130]:
		Specificity: 1.0
		Top 1 Acc = 47.34%
		Top 5 Acc = 75.78%                                 
		Loss/Iteration: 0.877227413976057

Epoch [104/130]:
		Specificity: 1.0
		Top 1 Acc = 47.56%
		Top 5 Acc = 75.84%                                 
		Loss/Iteration: 0.8866962167349729

Epoch [105/130]:
		Specificity: 1.0
		Top 1 Acc = 46.58%
		Top 5 Acc = 75.92%                                 
		Loss/Iteration: 0.8731167881580238

Epoch [106/130]:
		Specificity: 1.0
		Top 1 Acc = 47.26%
		Top 5 Acc = 75.74%                                 
		Loss/Iteration: 0.8714540182104842

Epoch [107/130]:
		Specificity: 1.0
		Top 1 Acc = 48.3%
		Top 5 Acc = 76.4%                                 
		Loss/Iteration: 0.8584647426297042

Epoch [108/130]:
		Specificity: 1.0
		Top 1 Acc = 48.1%
		Top 5 Acc = 75.72%                                 
		Loss/Iteration: 0.8594806611707265

Epoch [109/130]:
		Specificity: 1.0
		Top 1 Acc = 47.6%
		Top 5 Acc = 75.32%                                 
		Loss/Iteration: 0.854581945787438

Epoch [110/130]:
		Specificity: 1.0
		Top 1 Acc = 47.64%
		Top 5 Acc = 75.28%                                 
		Loss/Iteration: 0.8482344811358913

Epoch [111/130]:
		Specificity: 1.0
		Top 1 Acc = 47.72%
		Top 5 Acc = 76.1%                                 
		Loss/Iteration: 0.8413440667262132

Epoch [112/130]:
		Specificity: 1.0
		Top 1 Acc = 48.14%
		Top 5 Acc = 75.96%                                 
		Loss/Iteration: 0.8263609478334811

Epoch [113/130]:
		Specificity: 1.0
		Top 1 Acc = 47.2%
		Top 5 Acc = 76.1%                                 
		Loss/Iteration: 0.8253533556972715

Epoch [114/130]:
		Specificity: 1.0
		Top 1 Acc = 47.74%
		Top 5 Acc = 75.18%                                 
		Loss/Iteration: 0.8193666926500472

Epoch [115/130]:
		Specificity: 1.0
		Top 1 Acc = 48.16%
		Top 5 Acc = 75.98%                                 
		Loss/Iteration: 0.8218315173448487

Epoch [116/130]:
		Specificity: 1.0
		Top 1 Acc = 47.9%
		Top 5 Acc = 75.8%                                 
		Loss/Iteration: 0.8110768482173708

Epoch [117/130]:
		Specificity: 1.0
		Top 1 Acc = 47.04%
		Top 5 Acc = 75.06%                                 
		Loss/Iteration: 0.8095363584262404

Epoch [118/130]:
		Specificity: 1.0
		Top 1 Acc = 47.48%
		Top 5 Acc = 75.7%                                 
		Loss/Iteration: 0.7936027539809319

Epoch [119/130]:
		Specificity: 1.0
		Top 1 Acc = 48.18%
		Top 5 Acc = 76.08%                                 
		Loss/Iteration: 0.7978193841197274

Epoch [120/130]:
		Specificity: 1.0
		Top 1 Acc = 47.9%
		Top 5 Acc = 74.56%                                 
		Loss/Iteration: 0.8030895280059088

Epoch [121/130]:
		Specificity: 1.0
		Top 1 Acc = 46.3%
		Top 5 Acc = 75.36%                                 
		Loss/Iteration: 0.7886082541874864

Epoch [122/130]:
		Specificity: 1.0
		Top 1 Acc = 47.74%
		Top 5 Acc = 75.22%                                 
		Loss/Iteration: 0.7844484743069519

Epoch [123/130]:
		Specificity: 1.0
		Top 1 Acc = 47.1%
		Top 5 Acc = 75.72%                                 
		Loss/Iteration: 0.7792610203931954

Epoch [124/130]:
		Specificity: 1.0
		Top 1 Acc = 47.6%
		Top 5 Acc = 75.72%                                 
		Loss/Iteration: 0.7664111886935477

Epoch [125/130]:
		Specificity: 1.0
		Top 1 Acc = 46.4%
		Top 5 Acc = 74.58%                                 
		Loss/Iteration: 0.7637837798842653

Epoch [126/130]:
		Specificity: 1.0
		Top 1 Acc = 47.42%
		Top 5 Acc = 76.1%                                 
		Loss/Iteration: 0.773222289937125

Epoch [127/130]:
		Specificity: 1.0
		Top 1 Acc = 47.68%
		Top 5 Acc = 74.76%                                 
		Loss/Iteration: 0.7622968847016719

Epoch [128/130]:
		Specificity: 1.0
		Top 1 Acc = 46.92%
		Top 5 Acc = 75.22%                                 
		Loss/Iteration: 0.7509065166708421

Epoch [129/130]:
		Specificity: 1.0
		Top 1 Acc = 47.5%
		Top 5 Acc = 74.96%                                 
		Loss/Iteration: 0.7512835282832384

Epoch [130/130]:
		Specificity: 1.0
		Top 1 Acc = 47.32%
		Top 5 Acc = 75.16%                                 
		Loss/Iteration: 0.7446385752409697

------------------------------

||========================================||

Model: Branchy-AlexNet
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
BranchyAlexNet                           [1, 100]                  --
├─Sequential: 1-1                        [1, 64, 8, 8]             --
│    └─Conv2d: 2-1                       [1, 64, 16, 16]           1,792
│    └─MaxPool2d: 2-2                    [1, 64, 8, 8]             --
│    └─ReLU: 2-3                         [1, 64, 8, 8]             --
├─Sequential: 1-2                        [1, 128, 2, 2]            --
│    └─Conv2d: 2-4                       [1, 256, 8, 8]            147,712
│    └─MaxPool2d: 2-5                    [1, 256, 4, 4]            --
│    └─ReLU: 2-6                         [1, 256, 4, 4]            --
│    └─Conv2d: 2-7                       [1, 128, 4, 4]            295,040
│    └─MaxPool2d: 2-8                    [1, 128, 2, 2]            --
│    └─ReLU: 2-9                         [1, 128, 2, 2]            --
├─Sequential: 1-3                        [1, 100]                  --
│    └─Dropout: 2-10                     [1, 512]                  --
│    └─Linear: 2-11                      [1, 2048]                 1,050,624
│    └─ReLU: 2-12                        [1, 2048]                 --
│    └─Linear: 2-13                      [1, 100]                  204,900
├─Sequential: 1-4                        [1, 384, 4, 4]            --
│    └─Conv2d: 2-14                      [1, 192, 8, 8]            110,784
│    └─MaxPool2d: 2-15                   [1, 192, 4, 4]            --
│    └─ReLU: 2-16                        [1, 192, 4, 4]            --
│    └─Conv2d: 2-17                      [1, 384, 4, 4]            663,936
│    └─ReLU: 2-18                        [1, 384, 4, 4]            --
├─Sequential: 1-5                        [1, 256, 1, 1]            --
│    └─Conv2d: 2-19                      [1, 256, 2, 2]            884,992
│    └─MaxPool2d: 2-20                   [1, 256, 1, 1]            --
│    └─ReLU: 2-21                        [1, 256, 1, 1]            --
├─Sequential: 1-6                        [1, 100]                  --
│    └─Dropout: 2-22                     [1, 256]                  --
│    └─Linear: 2-23                      [1, 2048]                 526,336
│    └─ReLU: 2-24                        [1, 2048]                 --
│    └─Linear: 2-25                      [1, 100]                  204,900
├─Sequential: 1-7                        [1, 256, 2, 2]            --
│    └─Conv2d: 2-26                      [1, 256, 4, 4]            884,992
│    └─ReLU: 2-27                        [1, 256, 4, 4]            --
│    └─Conv2d: 2-28                      [1, 256, 4, 4]            590,080
│    └─MaxPool2d: 2-29                   [1, 256, 2, 2]            --
│    └─ReLU: 2-30                        [1, 256, 2, 2]            --
├─Sequential: 1-8                        [1, 100]                  --
│    └─Dropout: 2-31                     [1, 1024]                 --
│    └─Linear: 2-32                      [1, 2048]                 2,099,200
│    └─ReLU: 2-33                        [1, 2048]                 --
│    └─Dropout: 2-34                     [1, 2048]                 --
│    └─Linear: 2-35                      [1, 2048]                 4,196,352
│    └─ReLU: 2-36                        [1, 2048]                 --
│    └─Linear: 2-37                      [1, 100]                  204,900
==========================================================================================
Total params: 12,066,540
Trainable params: 12,066,540
Non-trainable params: 0
Total mult-adds (M): 67.97
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.57
Params size (MB): 48.27
Estimated Total Size (MB): 48.85
==========================================================================================

# Training iterations per epoch : 704

------------------------------
|          Training          |
------------------------------

Epoch [101/130]:
		Specificity: 1.0
		Top 1 Acc = 50.72%
		Top 5 Acc = 78.4%                                 
		Loss/Iteration: 3.318655701354146

Epoch [102/130]:
		Specificity: 1.0
		Top 1 Acc = 50.94%
		Top 5 Acc = 78.84%                                 
		Loss/Iteration: 3.292141426015984

Epoch [103/130]:
		Specificity: 1.0
		Top 1 Acc = 51.56%
		Top 5 Acc = 77.96%                                 
		Loss/Iteration: 3.270091769031503

Epoch [104/130]:
		Specificity: 1.0
		Top 1 Acc = 51.0%
		Top 5 Acc = 79.0%                                 
		Loss/Iteration: 3.2472025619989093

Epoch [105/130]:
		Specificity: 1.0
		Top 1 Acc = 51.24%
		Top 5 Acc = 78.26%                                 
		Loss/Iteration: 3.2251182293350045

Epoch [106/130]:
		Specificity: 1.0
		Top 1 Acc = 50.0%
		Top 5 Acc = 78.76%                                 
		Loss/Iteration: 3.228362435982986

Epoch [107/130]:
		Specificity: 1.0
		Top 1 Acc = 50.58%
		Top 5 Acc = 78.22%                                 
		Loss/Iteration: 3.201048907231201

Epoch [108/130]:
		Specificity: 1.0
		Top 1 Acc = 50.26%
		Top 5 Acc = 77.84%                                 
		Loss/Iteration: 3.18848113139922

Epoch [109/130]:
		Specificity: 1.0
		Top 1 Acc = 50.74%
		Top 5 Acc = 78.6%                                 
		Loss/Iteration: 3.177764280614528

Epoch [110/130]:
		Specificity: 1.0
		Top 1 Acc = 50.7%
		Top 5 Acc = 78.34%                                 
		Loss/Iteration: 3.170711026611653

Epoch [111/130]:
		Specificity: 1.0
		Top 1 Acc = 50.0%
		Top 5 Acc = 78.04%                                 
		Loss/Iteration: 3.1461701542139053

Epoch [112/130]:
		Specificity: 1.0
		Top 1 Acc = 51.14%
		Top 5 Acc = 78.98%                                 
		Loss/Iteration: 3.130231964655898

Epoch [113/130]:
		Specificity: 1.0
		Top 1 Acc = 50.6%
		Top 5 Acc = 78.46%                                 
		Loss/Iteration: 3.1350197538056155

Epoch [114/130]:
		Specificity: 1.0
		Top 1 Acc = 51.44%
		Top 5 Acc = 78.92%                                 
		Loss/Iteration: 3.104880172081969

Epoch [115/130]:
		Specificity: 1.0
		Top 1 Acc = 51.42%
		Top 5 Acc = 78.66%                                 
		Loss/Iteration: 3.0958799218589608

Epoch [116/130]:
		Specificity: 1.0
		Top 1 Acc = 51.6%
		Top 5 Acc = 78.4%                                 
		Loss/Iteration: 3.0920003432441843

Epoch [117/130]:
		Specificity: 1.0
		Top 1 Acc = 51.18%
		Top 5 Acc = 78.54%                                 
		Loss/Iteration: 3.0747944291003724

Epoch [118/130]:
		Specificity: 1.0
		Top 1 Acc = 51.66%
		Top 5 Acc = 78.72%                                 
		Loss/Iteration: 3.054505267095837

Epoch [119/130]:
		Specificity: 1.0
		Top 1 Acc = 50.2%
		Top 5 Acc = 78.8%                                 
		Loss/Iteration: 3.0434946621006187

Epoch [120/130]:
		Specificity: 1.0
		Top 1 Acc = 51.0%
		Top 5 Acc = 78.36%                                 
		Loss/Iteration: 3.0310584889216856

Epoch [121/130]:
		Specificity: 1.0
		Top 1 Acc = 50.34%
		Top 5 Acc = 77.88%                                 
		Loss/Iteration: 3.0255937305363743

Epoch [122/130]:
		Specificity: 1.0
		Top 1 Acc = 51.18%
		Top 5 Acc = 77.92%                                 
		Loss/Iteration: 3.025560127063231

Epoch [123/130]:
		Specificity: 1.0
		Top 1 Acc = 50.16%
		Top 5 Acc = 77.98%                                 
		Loss/Iteration: 3.0027560286901216

Epoch [124/130]:
		Specificity: 1.0
		Top 1 Acc = 50.26%
		Top 5 Acc = 78.22%                                 
		Loss/Iteration: 2.9866558216850865

Epoch [125/130]:
		Specificity: 1.0
		Top 1 Acc = 50.34%
		Top 5 Acc = 78.82%                                 
		Loss/Iteration: 2.9700251008299263

Epoch [126/130]:
		Specificity: 1.0
		Top 1 Acc = 50.54%
		Top 5 Acc = 78.56%                                 
		Loss/Iteration: 2.955768248404969

Epoch [127/130]:
		Specificity: 1.0
		Top 1 Acc = 50.86%
		Top 5 Acc = 78.3%                                 
		Loss/Iteration: 2.952628846195611

Epoch [128/130]:
		Specificity: 1.0
		Top 1 Acc = 50.94%
		Top 5 Acc = 77.94%                                 
		Loss/Iteration: 2.9504049113866957

Epoch [129/130]:
		Specificity: 1.0
		Top 1 Acc = 51.44%
		Top 5 Acc = 78.72%                                 
		Loss/Iteration: 2.935905864292925

Epoch [130/130]:
		Specificity: 1.0
		Top 1 Acc = 50.36%
		Top 5 Acc = 77.88%                                 
		Loss/Iteration: 2.9242055656557735

------------------------------

||========================================||

Model: Sem-HBN
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
SemHBN                                   [1, 100]                  --
├─Sequential: 1-1                        [1, 64, 8, 8]             --
│    └─Conv2d: 2-1                       [1, 64, 16, 16]           1,792
│    └─MaxPool2d: 2-2                    [1, 64, 8, 8]             --
│    └─ReLU: 2-3                         [1, 64, 8, 8]             --
├─Sequential: 1-2                        [1, 128, 2, 2]            --
│    └─Conv2d: 2-4                       [1, 256, 8, 8]            147,712
│    └─MaxPool2d: 2-5                    [1, 256, 4, 4]            --
│    └─ReLU: 2-6                         [1, 256, 4, 4]            --
│    └─Conv2d: 2-7                       [1, 128, 4, 4]            295,040
│    └─MaxPool2d: 2-8                    [1, 128, 2, 2]            --
│    └─ReLU: 2-9                         [1, 128, 2, 2]            --
├─Sequential: 1-3                        [1, 20]                   --
│    └─Dropout: 2-10                     [1, 512]                  --
│    └─Linear: 2-11                      [1, 2048]                 1,050,624
│    └─ReLU: 2-12                        [1, 2048]                 --
│    └─Linear: 2-13                      [1, 20]                   40,980
├─Sequential: 1-4                        [1, 384, 4, 4]            --
│    └─Conv2d: 2-14                      [1, 192, 8, 8]            110,784
│    └─MaxPool2d: 2-15                   [1, 192, 4, 4]            --
│    └─ReLU: 2-16                        [1, 192, 4, 4]            --
│    └─Conv2d: 2-17                      [1, 384, 4, 4]            663,936
│    └─ReLU: 2-18                        [1, 384, 4, 4]            --
├─Sequential: 1-5                        [1, 256, 1, 1]            --
│    └─Conv2d: 2-19                      [1, 256, 2, 2]            884,992
│    └─MaxPool2d: 2-20                   [1, 256, 1, 1]            --
│    └─ReLU: 2-21                        [1, 256, 1, 1]            --
├─Sequential: 1-6                        [1, 20]                   --
│    └─Dropout: 2-22                     [1, 256]                  --
│    └─Linear: 2-23                      [1, 2048]                 526,336
│    └─ReLU: 2-24                        [1, 2048]                 --
│    └─Linear: 2-25                      [1, 20]                   40,980
├─Sequential: 1-7                        [1, 256, 2, 2]            --
│    └─Conv2d: 2-26                      [1, 256, 4, 4]            884,992
│    └─ReLU: 2-27                        [1, 256, 4, 4]            --
│    └─Conv2d: 2-28                      [1, 256, 4, 4]            590,080
│    └─MaxPool2d: 2-29                   [1, 256, 2, 2]            --
│    └─ReLU: 2-30                        [1, 256, 2, 2]            --
├─Sequential: 1-8                        [1, 100]                  --
│    └─Dropout: 2-31                     [1, 1024]                 --
│    └─Linear: 2-32                      [1, 2048]                 2,099,200
│    └─ReLU: 2-33                        [1, 2048]                 --
│    └─Dropout: 2-34                     [1, 2048]                 --
│    └─Linear: 2-35                      [1, 2048]                 4,196,352
│    └─ReLU: 2-36                        [1, 2048]                 --
│    └─Linear: 2-37                      [1, 100]                  204,900
==========================================================================================
Total params: 11,738,700
Trainable params: 11,738,700
Non-trainable params: 0
Total mult-adds (M): 67.65
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.57
Params size (MB): 46.95
Estimated Total Size (MB): 47.53
==========================================================================================

# Training iterations per epoch : 704

------------------------------
|          Training          |
------------------------------

Epoch [101/130]:
		Specificity: 1.0
		Top 1 Acc = 49.8%
		Top 5 Acc = 76.96%                                 
		Loss/Iteration: 2.2781927329911427

Epoch [102/130]:
		Specificity: 1.0
		Top 1 Acc = 50.02%
		Top 5 Acc = 77.22%                                 
		Loss/Iteration: 2.281007355925712

Epoch [103/130]:
		Specificity: 1.0
		Top 1 Acc = 49.44%
		Top 5 Acc = 76.44%                                 
		Loss/Iteration: 2.2450656072998587

Epoch [104/130]:
		Specificity: 1.0
		Top 1 Acc = 49.64%
		Top 5 Acc = 76.66%                                 
		Loss/Iteration: 2.2396411690860987

Epoch [105/130]:
		Specificity: 1.0
		Top 1 Acc = 48.86%
		Top 5 Acc = 77.16%                                 
		Loss/Iteration: 2.2330256013030354

Epoch [106/130]:
		Specificity: 1.0
		Top 1 Acc = 49.58%
		Top 5 Acc = 76.74%                                 
		Loss/Iteration: 2.235920063981956

Epoch [107/130]:
		Specificity: 1.0
		Top 1 Acc = 49.96%
		Top 5 Acc = 76.78%                                 
		Loss/Iteration: 2.215984682129188

Epoch [108/130]:
		Specificity: 1.0
		Top 1 Acc = 50.1%
		Top 5 Acc = 77.48%                                 
		Loss/Iteration: 2.213228744708679

Epoch [109/130]:
		Specificity: 1.0
		Top 1 Acc = 48.66%
		Top 5 Acc = 76.46%                                 
		Loss/Iteration: 2.1919555584476753

Epoch [110/130]:
		Specificity: 1.0
		Top 1 Acc = 49.04%
		Top 5 Acc = 76.82%                                 
		Loss/Iteration: 2.184684757481922

Epoch [111/130]:
		Specificity: 1.0
		Top 1 Acc = 48.82%
		Top 5 Acc = 76.82%                                 
		Loss/Iteration: 2.175825644961812

Epoch [112/130]:
		Specificity: 1.0
		Top 1 Acc = 49.0%
		Top 5 Acc = 77.06%                                 
		Loss/Iteration: 2.1690190356563437

Epoch [113/130]:
		Specificity: 1.0
		Top 1 Acc = 49.18%
		Top 5 Acc = 77.12%                                 
		Loss/Iteration: 2.1511011640117927

Epoch [114/130]:
		Specificity: 1.0
		Top 1 Acc = 50.12%
		Top 5 Acc = 76.58%                                 
		Loss/Iteration: 2.1537290339104156

Epoch [115/130]:
		Specificity: 1.0
		Top 1 Acc = 49.34%
		Top 5 Acc = 76.68%                                 
		Loss/Iteration: 2.1420504828407005

Epoch [116/130]:
		Specificity: 1.0
		Top 1 Acc = 49.32%
		Top 5 Acc = 77.78%                                 
		Loss/Iteration: 2.138594137166034

Epoch [117/130]:
		Specificity: 1.0
		Top 1 Acc = 48.9%
		Top 5 Acc = 77.0%                                 
		Loss/Iteration: 2.1471272102472456

Epoch [118/130]:
		Specificity: 0.9873417721518988
		Top 1 Acc = 49.44%
		Top 5 Acc = 76.2%                                 
		Loss/Iteration: 2.1194223678586157

Epoch [119/130]:
		Specificity: 0.9746835443037974
		Top 1 Acc = 49.9%
		Top 5 Acc = 76.86%                                 
		Loss/Iteration: 2.1167069622738794

Epoch [120/130]:
		Specificity: 1.0
		Top 1 Acc = 48.78%
		Top 5 Acc = 76.88%                                 
		Loss/Iteration: 2.105541765859181

Epoch [121/130]:
		Specificity: 1.0
		Top 1 Acc = 48.46%
		Top 5 Acc = 76.2%                                 
		Loss/Iteration: 2.1015484747900204

Epoch [122/130]:
		Specificity: 1.0
		Top 1 Acc = 48.5%
		Top 5 Acc = 76.5%                                 
		Loss/Iteration: 2.066362372345545

Epoch [123/130]:
		Specificity: 0.9873417721518988
		Top 1 Acc = 50.7%
		Top 5 Acc = 76.66%                                 
		Loss/Iteration: 2.0787718088620086

Epoch [124/130]:
		Specificity: 1.0
		Top 1 Acc = 49.08%
		Top 5 Acc = 76.22%                                 
		Loss/Iteration: 2.0648643181405286

Epoch [125/130]:
		Specificity: 0.9873417721518988
		Top 1 Acc = 49.22%
		Top 5 Acc = 76.74%                                 
		Loss/Iteration: 2.0692451509901066

Epoch [126/130]:
		Specificity: 0.9873417721518988
		Top 1 Acc = 49.44%
		Top 5 Acc = 76.96%                                 
		Loss/Iteration: 2.0451494836333124

Epoch [127/130]:
		Specificity: 1.0
		Top 1 Acc = 49.18%
		Top 5 Acc = 77.1%                                 
		Loss/Iteration: 2.043216157873923

Epoch [128/130]:
		Specificity: 0.9873417721518988
		Top 1 Acc = 50.5%
		Top 5 Acc = 76.5%                                 
		Loss/Iteration: 2.03167804279788

Epoch [129/130]:
		Specificity: 1.0
		Top 1 Acc = 49.54%
		Top 5 Acc = 76.62%                                 
		Loss/Iteration: 2.030231849544428

Epoch [130/130]:
		Specificity: 0.9873417721518988
		Top 1 Acc = 50.1%
		Top 5 Acc = 77.12%                                 
		Loss/Iteration: 2.0333560566333206

------------------------------

||========================================||

Model: Super-HBN
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
SuperHBN                                 [1, 20]                   --
├─Sequential: 1-1                        [1, 64, 8, 8]             --
│    └─Conv2d: 2-1                       [1, 64, 16, 16]           1,792
│    └─MaxPool2d: 2-2                    [1, 64, 8, 8]             --
│    └─ReLU: 2-3                         [1, 64, 8, 8]             --
├─Sequential: 1-2                        [1, 128, 2, 2]            --
│    └─Conv2d: 2-4                       [1, 256, 8, 8]            147,712
│    └─MaxPool2d: 2-5                    [1, 256, 4, 4]            --
│    └─ReLU: 2-6                         [1, 256, 4, 4]            --
│    └─Conv2d: 2-7                       [1, 128, 4, 4]            295,040
│    └─MaxPool2d: 2-8                    [1, 128, 2, 2]            --
│    └─ReLU: 2-9                         [1, 128, 2, 2]            --
├─Sequential: 1-3                        [1, 2048]                 --
│    └─Dropout: 2-10                     [1, 512]                  --
│    └─Linear: 2-11                      [1, 2048]                 1,050,624
│    └─ReLU: 2-12                        [1, 2048]                 --
├─Sequential: 1-4                        [1, 100]                  --
│    └─Linear: 2-13                      [1, 100]                  204,900
├─Sequential: 1-5                        [1, 20]                   --
│    └─Linear: 2-14                      [1, 20]                   40,980
├─Sequential: 1-6                        [1, 384, 4, 4]            --
│    └─Conv2d: 2-15                      [1, 192, 8, 8]            110,784
│    └─MaxPool2d: 2-16                   [1, 192, 4, 4]            --
│    └─ReLU: 2-17                        [1, 192, 4, 4]            --
│    └─Conv2d: 2-18                      [1, 384, 4, 4]            663,936
│    └─ReLU: 2-19                        [1, 384, 4, 4]            --
├─Sequential: 1-7                        [1, 256, 1, 1]            --
│    └─Conv2d: 2-20                      [1, 256, 2, 2]            884,992
│    └─MaxPool2d: 2-21                   [1, 256, 1, 1]            --
│    └─ReLU: 2-22                        [1, 256, 1, 1]            --
├─Sequential: 1-8                        [1, 2048]                 --
│    └─Dropout: 2-23                     [1, 256]                  --
│    └─Linear: 2-24                      [1, 2048]                 526,336
│    └─ReLU: 2-25                        [1, 2048]                 --
├─Sequential: 1-9                        [1, 100]                  --
│    └─Linear: 2-26                      [1, 100]                  204,900
├─Sequential: 1-10                       [1, 20]                   --
│    └─Linear: 2-27                      [1, 20]                   40,980
├─Sequential: 1-11                       [1, 256, 2, 2]            --
│    └─Conv2d: 2-28                      [1, 256, 4, 4]            884,992
│    └─ReLU: 2-29                        [1, 256, 4, 4]            --
│    └─Conv2d: 2-30                      [1, 256, 4, 4]            590,080
│    └─MaxPool2d: 2-31                   [1, 256, 2, 2]            --
│    └─ReLU: 2-32                        [1, 256, 2, 2]            --
├─Sequential: 1-12                       [1, 2048]                 --
│    └─Dropout: 2-33                     [1, 1024]                 --
│    └─Linear: 2-34                      [1, 2048]                 2,099,200
│    └─ReLU: 2-35                        [1, 2048]                 --
│    └─Dropout: 2-36                     [1, 2048]                 --
│    └─Linear: 2-37                      [1, 2048]                 4,196,352
│    └─ReLU: 2-38                        [1, 2048]                 --
├─Sequential: 1-13                       [1, 100]                  --
│    └─Linear: 2-39                      [1, 100]                  204,900
├─Sequential: 1-14                       [1, 20]                   --
│    └─Linear: 2-40                      [1, 20]                   40,980
==========================================================================================
Total params: 12,189,480
Trainable params: 12,189,480
Non-trainable params: 0
Total mult-adds (M): 68.10
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.57
Params size (MB): 48.76
Estimated Total Size (MB): 49.34
==========================================================================================

# Training iterations per epoch : 704

------------------------------
|          Training          |
------------------------------

Epoch [101/130]:
		Specificity: 0.4936708860759494
		Top 1 Acc = 58.38%
		Top 5 Acc = 84.82%                                 
		Loss/Iteration: 6.24767829714851

Epoch [102/130]:
		Specificity: 0.7721518987341772
		Top 1 Acc = 53.96%
		Top 5 Acc = 80.56%                                 
		Loss/Iteration: 6.202943884513595

Epoch [103/130]:
		Specificity: 0.620253164556962
		Top 1 Acc = 55.54%
		Top 5 Acc = 82.8%                                 
		Loss/Iteration: 6.171008140526035

Epoch [104/130]:
		Specificity: 0.3670886075949367
		Top 1 Acc = 59.58%
		Top 5 Acc = 86.08%                                 
		Loss/Iteration: 6.156758232211525

Epoch [105/130]:
		Specificity: 0.620253164556962
		Top 1 Acc = 56.44%
		Top 5 Acc = 82.9%                                 
		Loss/Iteration: 6.091185751963746

Epoch [106/130]:
		Specificity: 0.5443037974683544
		Top 1 Acc = 58.02%
		Top 5 Acc = 84.16%                                 
		Loss/Iteration: 6.116910782050002

Epoch [107/130]:
		Specificity: 0.7721518987341772
		Top 1 Acc = 53.52%
		Top 5 Acc = 80.52%                                 
		Loss/Iteration: 6.049404542215846

Epoch [108/130]:
		Specificity: 0.4430379746835443
		Top 1 Acc = 58.88%
		Top 5 Acc = 85.3%                                 
		Loss/Iteration: 6.038602661680091

Epoch [109/130]:
		Specificity: 0.8607594936708861
		Top 1 Acc = 52.58%
		Top 5 Acc = 80.3%                                 
		Loss/Iteration: 6.010192436250773

Epoch [110/130]:
		Specificity: 0.6455696202531646
		Top 1 Acc = 55.52%
		Top 5 Acc = 82.66%                                 
		Loss/Iteration: 5.971790293400938

Epoch [111/130]:
		Specificity: 0.620253164556962
		Top 1 Acc = 55.82%
		Top 5 Acc = 83.22%                                 
		Loss/Iteration: 5.935828431763432

Epoch [112/130]:
		Specificity: 0.5822784810126582
		Top 1 Acc = 56.92%
		Top 5 Acc = 83.86%                                 
		Loss/Iteration: 5.8991505984555594

Epoch [113/130]:
		Specificity: 0.6455696202531646
		Top 1 Acc = 55.64%
		Top 5 Acc = 82.78%                                 
		Loss/Iteration: 5.9044527851722455

Epoch [114/130]:
		Specificity: 0.6708860759493671
		Top 1 Acc = 55.82%
		Top 5 Acc = 82.9%                                 
		Loss/Iteration: 5.880336989394643

Epoch [115/130]:
		Specificity: 0.6329113924050633
		Top 1 Acc = 56.6%
		Top 5 Acc = 83.44%                                 
		Loss/Iteration: 5.885944774543697

Epoch [116/130]:
		Specificity: 0.6962025316455697
		Top 1 Acc = 54.38%
		Top 5 Acc = 81.86%                                 
		Loss/Iteration: 5.8124409507621415

Epoch [117/130]:
		Specificity: 0.810126582278481
		Top 1 Acc = 53.78%
		Top 5 Acc = 80.6%                                 
		Loss/Iteration: 5.780560759658163

Epoch [118/130]:
		Specificity: 0.8354430379746836
		Top 1 Acc = 53.82%
		Top 5 Acc = 80.12%                                 
		Loss/Iteration: 5.792406545782631

Epoch [119/130]:
		Specificity: 0.7468354430379747
		Top 1 Acc = 53.68%
		Top 5 Acc = 81.46%                                 
		Loss/Iteration: 5.7943327403204

Epoch [120/130]:
		Specificity: 0.7215189873417721
		Top 1 Acc = 54.38%
		Top 5 Acc = 81.58%                                 
		Loss/Iteration: 5.730916118757292

Epoch [121/130]:
		Specificity: 0.8227848101265823
		Top 1 Acc = 53.52%
		Top 5 Acc = 80.52%                                 
		Loss/Iteration: 5.714565402404829

Epoch [122/130]:
		Specificity: 0.7848101265822784
		Top 1 Acc = 55.0%
		Top 5 Acc = 81.24%                                 
		Loss/Iteration: 5.731561869382858

Epoch [123/130]:
		Specificity: 0.8354430379746836
		Top 1 Acc = 53.24%
		Top 5 Acc = 80.52%                                 
		Loss/Iteration: 5.665489453145049

Epoch [124/130]:
		Specificity: 0.8987341772151899
		Top 1 Acc = 52.72%
		Top 5 Acc = 79.84%                                 
		Loss/Iteration: 5.6403058178045535

Epoch [125/130]:
		Specificity: 0.7848101265822784
		Top 1 Acc = 54.24%
		Top 5 Acc = 81.36%                                 
		Loss/Iteration: 5.639143346046859

Epoch [126/130]:
		Specificity: 0.759493670886076
		Top 1 Acc = 53.96%
		Top 5 Acc = 81.2%                                 
		Loss/Iteration: 5.583134509284388

Epoch [127/130]:
		Specificity: 0.8607594936708861
		Top 1 Acc = 53.88%
		Top 5 Acc = 80.56%                                 
		Loss/Iteration: 5.563597676767544

Epoch [128/130]:
		Specificity: 0.8227848101265823
		Top 1 Acc = 53.44%
		Top 5 Acc = 80.98%                                 
		Loss/Iteration: 5.54137082431804

Epoch [129/130]:
		Specificity: 0.8860759493670886
		Top 1 Acc = 52.04%
		Top 5 Acc = 78.76%                                 
		Loss/Iteration: 5.545397566462105

Epoch [130/130]:
		Specificity: 0.7468354430379747
		Top 1 Acc = 53.62%
		Top 5 Acc = 81.44%                                 
		Loss/Iteration: 5.5247035964646125

------------------------------

||========================================||

