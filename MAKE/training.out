Args:
	mode: training
	batch_size: 64
	lr: 0.00015
	pt_lr: 1e-05
	weight_decay: 0.0005
	device: cuda
	num_epochs: 60


Model: TD-HBN
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
TD_HBN                                   [1, 100]                  --
├─Sequential: 1-1                        [1, 64, 8, 8]             --
│    └─Conv2d: 2-1                       [1, 64, 16, 16]           1,792
│    └─MaxPool2d: 2-2                    [1, 64, 8, 8]             --
│    └─ReLU: 2-3                         [1, 64, 8, 8]             --
├─Sequential: 1-2                        [1, 128, 2, 2]            --
│    └─Conv2d: 2-4                       [1, 256, 8, 8]            147,712
│    └─MaxPool2d: 2-5                    [1, 256, 4, 4]            --
│    └─ReLU: 2-6                         [1, 256, 4, 4]            --
│    └─Conv2d: 2-7                       [1, 128, 4, 4]            295,040
│    └─MaxPool2d: 2-8                    [1, 128, 2, 2]            --
│    └─ReLU: 2-9                         [1, 128, 2, 2]            --
├─Sequential: 1-3                        [1, 2048]                 --
│    └─Dropout: 2-10                     [1, 512]                  --
│    └─Linear: 2-11                      [1, 2048]                 1,050,624
│    └─ReLU: 2-12                        [1, 2048]                 --
├─Sequential: 1-4                        [1, 100]                  --
│    └─Linear: 2-13                      [1, 100]                  204,900
├─Sequential: 1-5                        [1, 20]                   --
│    └─Linear: 2-14                      [1, 20]                   40,980
├─Sequential: 1-6                        [1, 2]                    --
│    └─Linear: 2-15                      [1, 2]                    4,098
├─Sequential: 1-7                        [1, 384, 4, 4]            --
│    └─Conv2d: 2-16                      [1, 192, 8, 8]            110,784
│    └─MaxPool2d: 2-17                   [1, 192, 4, 4]            --
│    └─ReLU: 2-18                        [1, 192, 4, 4]            --
│    └─Conv2d: 2-19                      [1, 384, 4, 4]            663,936
│    └─ReLU: 2-20                        [1, 384, 4, 4]            --
├─Sequential: 1-8                        [1, 256, 1, 1]            --
│    └─Conv2d: 2-21                      [1, 256, 2, 2]            884,992
│    └─MaxPool2d: 2-22                   [1, 256, 1, 1]            --
│    └─ReLU: 2-23                        [1, 256, 1, 1]            --
├─Sequential: 1-9                        [1, 2048]                 --
│    └─Dropout: 2-24                     [1, 256]                  --
│    └─Linear: 2-25                      [1, 2048]                 526,336
│    └─ReLU: 2-26                        [1, 2048]                 --
├─Sequential: 1-10                       [1, 100]                  --
│    └─Linear: 2-27                      [1, 100]                  204,900
├─Sequential: 1-11                       [1, 20]                   --
│    └─Linear: 2-28                      [1, 20]                   40,980
├─Sequential: 1-12                       [1, 256, 2, 2]            --
│    └─Conv2d: 2-29                      [1, 256, 4, 4]            884,992
│    └─ReLU: 2-30                        [1, 256, 4, 4]            --
│    └─Conv2d: 2-31                      [1, 256, 4, 4]            590,080
│    └─MaxPool2d: 2-32                   [1, 256, 2, 2]            --
│    └─ReLU: 2-33                        [1, 256, 2, 2]            --
├─Sequential: 1-13                       [1, 2048]                 --
│    └─Dropout: 2-34                     [1, 1024]                 --
│    └─Linear: 2-35                      [1, 2048]                 2,099,200
│    └─ReLU: 2-36                        [1, 2048]                 --
│    └─Dropout: 2-37                     [1, 2048]                 --
│    └─Linear: 2-38                      [1, 2048]                 4,196,352
│    └─ReLU: 2-39                        [1, 2048]                 --
├─Sequential: 1-14                       [1, 100]                  --
│    └─Linear: 2-40                      [1, 100]                  204,900
├─Sequential: 1-15                       [1, 20]                   --
│    └─Linear: 2-41                      [1, 20]                   40,980
==========================================================================================
Total params: 12,193,578
Trainable params: 12,193,578
Non-trainable params: 0
Total mult-adds (M): 68.10
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.57
Params size (MB): 48.77
Estimated Total Size (MB): 49.35
==========================================================================================

# Post-Training iterations per epoch : 704

----------------------------------------
|             Post-Training            |
----------------------------------------

Epoch [1/30]:
		Specificity: 0.912
		Top 1 Acc = 52.2%
		Top 5 Acc = 78.56%                                 
		Loss/Iteration: 5.249252586879513

Epoch [2/30]:
		Specificity: 0.8988
		Top 1 Acc = 51.88%
		Top 5 Acc = 78.54%                                 
		Loss/Iteration: 5.216475513171066

Epoch [3/30]:
		Specificity: 0.8854
		Top 1 Acc = 52.12%
		Top 5 Acc = 78.62%                                 
		Loss/Iteration: 5.207784596491944

Epoch [4/30]:
		Specificity: 0.8814
		Top 1 Acc = 52.32%
		Top 5 Acc = 79.04%                                 
		Loss/Iteration: 5.178964990106496

Epoch [5/30]:
		Specificity: 0.9016
		Top 1 Acc = 52.0%
		Top 5 Acc = 78.42%                                 
		Loss/Iteration: 5.171860486268997

Epoch [6/30]:
		Specificity: 0.8958
		Top 1 Acc = 52.36%
		Top 5 Acc = 78.62%                                 
		Loss/Iteration: 5.161974159831351

Epoch [7/30]:
		Specificity: 0.8528
		Top 1 Acc = 52.82%
		Top 5 Acc = 79.2%                                 
		Loss/Iteration: 5.163456540893424

Epoch [8/30]:
		Specificity: 0.8788
		Top 1 Acc = 52.02%
		Top 5 Acc = 78.46%                                 
		Loss/Iteration: 5.149072660641237

Epoch [9/30]:
		Specificity: 0.8692
		Top 1 Acc = 53.2%
		Top 5 Acc = 78.96%                                 
		Loss/Iteration: 5.149469290267337

Epoch [10/30]:
		Specificity: 0.858
		Top 1 Acc = 52.66%
		Top 5 Acc = 79.06%                                 
		Loss/Iteration: 5.145035474137827

Epoch [11/30]:
		Specificity: 0.8792
		Top 1 Acc = 53.9%
		Top 5 Acc = 79.32%                                 
		Loss/Iteration: 5.140574139627543

Epoch [12/30]:
		Specificity: 0.8638
		Top 1 Acc = 54.2%
		Top 5 Acc = 78.74%                                 
		Loss/Iteration: 5.139829492704435

Epoch [13/30]:
		Specificity: 0.8654
		Top 1 Acc = 53.5%
		Top 5 Acc = 79.1%                                 
		Loss/Iteration: 5.1381426291032275

Epoch [14/30]:
		Specificity: 0.8604
		Top 1 Acc = 53.54%
		Top 5 Acc = 79.46%                                 
		Loss/Iteration: 5.126962503248995

Epoch [15/30]:
		Specificity: 0.8448
		Top 1 Acc = 53.98%
		Top 5 Acc = 79.88%                                 
		Loss/Iteration: 5.127807239239866

Epoch [16/30]:
		Specificity: 0.8736
		Top 1 Acc = 52.82%
		Top 5 Acc = 78.8%                                 
		Loss/Iteration: 5.126544749872251

Epoch [17/30]:
		Specificity: 0.8512
		Top 1 Acc = 53.58%
		Top 5 Acc = 79.66%                                 
		Loss/Iteration: 5.136389768936417

Epoch [18/30]:
		Specificity: 0.8566
		Top 1 Acc = 53.72%
		Top 5 Acc = 79.4%                                 
		Loss/Iteration: 5.136617743833498

Epoch [19/30]:
		Specificity: 0.8388
		Top 1 Acc = 54.04%
		Top 5 Acc = 79.84%                                 
		Loss/Iteration: 5.131072391501882

Epoch [20/30]:
		Specificity: 0.854
		Top 1 Acc = 53.52%
		Top 5 Acc = 79.12%                                 
		Loss/Iteration: 5.119268612428145

Epoch [21/30]:
		Specificity: 0.8722
		Top 1 Acc = 53.54%
		Top 5 Acc = 79.18%                                 
		Loss/Iteration: 5.115442296998068

Epoch [22/30]:
		Specificity: 0.8624
		Top 1 Acc = 53.14%
		Top 5 Acc = 79.02%                                 
		Loss/Iteration: 5.1104229702190915

Epoch [23/30]:
		Specificity: 0.8738
		Top 1 Acc = 53.34%
		Top 5 Acc = 78.84%                                 
		Loss/Iteration: 5.110051137479869

Epoch [24/30]:
		Specificity: 0.8602
		Top 1 Acc = 52.96%
		Top 5 Acc = 78.98%                                 
		Loss/Iteration: 5.126028645445

Epoch [25/30]:
		Specificity: 0.8546
		Top 1 Acc = 53.78%
		Top 5 Acc = 79.7%                                 
		Loss/Iteration: 5.1194470795718106

Epoch [26/30]:
		Specificity: 0.836
		Top 1 Acc = 53.9%
		Top 5 Acc = 79.76%                                 
		Loss/Iteration: 5.111394699324261

Epoch [27/30]:
		Specificity: 0.8422
		Top 1 Acc = 54.74%
		Top 5 Acc = 79.56%                                 
		Loss/Iteration: 5.096332438290119

Epoch [28/30]:
		Specificity: 0.8436
		Top 1 Acc = 53.54%
		Top 5 Acc = 79.34%                                 
		Loss/Iteration: 5.112302482128143

Epoch [29/30]:
		Specificity: 0.8788
		Top 1 Acc = 53.16%
		Top 5 Acc = 78.58%                                 
		Loss/Iteration: 5.1103100553154945

Epoch [30/30]:
		Specificity: 0.8502
		Top 1 Acc = 54.1%
		Top 5 Acc = 79.42%                                 
		Loss/Iteration: 5.102249952541157


||========================================||

