Args:
	mode: training
	batch_size: 256
	lr: 0.0005
	weight_decay: 0.0001
	device: cuda
	num_epochs: 5


Model == AlexNet

torch.Size([1, 3, 32, 32])
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
AlexNet                                  [1, 100]                  --
├─Sequential: 1-1                        [1, 256, 2, 2]            --
│    └─Conv2d: 2-1                       [1, 64, 16, 16]           1,792
│    └─MaxPool2d: 2-2                    [1, 64, 8, 8]             --
│    └─ReLU: 2-3                         [1, 64, 8, 8]             --
│    └─Conv2d: 2-4                       [1, 192, 8, 8]            110,784
│    └─MaxPool2d: 2-5                    [1, 192, 4, 4]            --
│    └─ReLU: 2-6                         [1, 192, 4, 4]            --
│    └─Conv2d: 2-7                       [1, 384, 4, 4]            663,936
│    └─ReLU: 2-8                         [1, 384, 4, 4]            --
│    └─Conv2d: 2-9                       [1, 256, 4, 4]            884,992
│    └─ReLU: 2-10                        [1, 256, 4, 4]            --
│    └─Conv2d: 2-11                      [1, 256, 4, 4]            590,080
│    └─MaxPool2d: 2-12                   [1, 256, 2, 2]            --
│    └─ReLU: 2-13                        [1, 256, 2, 2]            --
├─Sequential: 1-2                        [1, 100]                  --
│    └─Dropout: 2-14                     [1, 1024]                 --
│    └─Linear: 2-15                      [1, 4096]                 4,198,400
│    └─ReLU: 2-16                        [1, 4096]                 --
│    └─Dropout: 2-17                     [1, 4096]                 --
│    └─Linear: 2-18                      [1, 4096]                 16,781,312
│    └─ReLU: 2-19                        [1, 4096]                 --
│    └─Linear: 2-20                      [1, 100]                  409,700
==========================================================================================
Total params: 23,640,996
Trainable params: 23,640,996
Non-trainable params: 0
Total mult-adds (M): 63.16
==========================================================================================
Input size (MB): 0.01
Forward/backward pass size (MB): 0.41
Params size (MB): 94.56
Estimated Total Size (MB): 94.99
==========================================================================================

# Training iterations per epoch : 176

------------------------------
|          Training          |
------------------------------

Epoch [1/5]:                             
		Top 1 Acc = 4.58%
		Top 5 Acc = 21.86%                                 
		Loss/Iteration: 4.2969317178834565

Epoch [2/5]:                             
		Top 1 Acc = 10.16%
		Top 5 Acc = 31.82%                                 
		Loss/Iteration: 3.89165639470924

Epoch [3/5]:                             
		Top 1 Acc = 13.62%
		Top 5 Acc = 39.6%                                 
		Loss/Iteration: 3.649808932434429

Epoch [4/5]:                             
		Top 1 Acc = 16.08%
		Top 5 Acc = 44.68%                                 
		Loss/Iteration: 3.4593643031337042

Traceback (most recent call last):
  File "/home/phoenix/base/active/Class-Granular-Classifications/MAKE/../main.py", line 163, in <module>
    MODE_MAP[args.mode](data, MODELS, TRAINER, args, MODEL_PATH)
  File "/home/phoenix/base/active/Class-Granular-Classifications/MAKE/../main.py", line 81, in training
    trainer.train(filepath=f'{_model_path}/{model_name}.pth')
  File "/home/phoenix/base/active/Class-Granular-Classifications/processing/training.py", line 79, in train
    for index, (images, labels) in enumerate(self.train_loader):
  File "/home/phoenix/base/py3_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/home/phoenix/base/py3_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1328, in _next_data
    idx, data = self._get_data()
  File "/home/phoenix/base/py3_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1294, in _get_data
    success, data = self._try_get_data()
  File "/home/phoenix/base/py3_venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1132, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/usr/lib/python3.10/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
  File "/home/phoenix/base/py3_venv/lib/python3.10/site-packages/torch/multiprocessing/reductions.py", line 307, in rebuild_storage_fd
    fd = df.detach()
  File "/usr/lib/python3.10/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/usr/lib/python3.10/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 509, in Client
    deliver_challenge(c, authkey)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 738, in deliver_challenge
    connection.send_bytes(CHALLENGE + message)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
KeyboardInterrupt
